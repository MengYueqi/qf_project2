{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243e7dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# Multi-Ticker | GRU(classification) → Online calibration → r̂   \n",
    "# Fixed split: Train/Valid/Test; train on Train+Valid only; rolling forecast on Test\n",
    "# - Iterate tickers in CSV (multi-level columns: [PriceField, Ticker])\n",
    "# - Retain: online ridge regression calibration + online mean matching + \"Scheme A: rebasing by blocks\" (for display only)\n",
    "# - For each ticker:\n",
    "#     * Train (until 2020-12-31) + Valid (until 2022-12-31); freeze parameters\n",
    "#     * Rolling forecast on Test; output {TICKER}.csv -> [Date, PredictedPrice]\n",
    "#     * Plot 1 \"Actual vs Predicted (rebased)\" chart; print OOS metrics (MSE, R2, IC, Hit, Sharpe)\n",
    "# - Extra output: OOS_summary.csv (summary of test metrics for all tickers)\n",
    "# ==============================================================\n",
    "\n",
    "import os, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm.auto import tqdm\n",
    "from collections import deque\n",
    "\n",
    "tqdm.monitor_interval = 0\n",
    "\n",
    "# ---------------- Config ----------------\n",
    "START_FROM_IDX = 0\n",
    "\n",
    "DATA_DIR   = \"./data\"\n",
    "OUT_DIR    = \"./output\"\n",
    "PRICE_FILE = os.path.join(DATA_DIR, \"price_data_full.csv\")\n",
    "\n",
    "START      = \"2010-01-01\"\n",
    "END        = None  \n",
    "\n",
    "# 固定切分边界\n",
    "TRAIN_END = \"2020-12-31\"\n",
    "VAL_END   = \"2022-12-31\"   # VAL_END(含)之后即为 Testing\n",
    "\n",
    "# 序列与滚动\n",
    "SEQ_LEN        = 20\n",
    "MIN_TRAIN_DAYS = 40\n",
    "\n",
    "# 训练\n",
    "BATCH_SIZE   = 512\n",
    "LR           = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "MAX_EPOCHS   = 120\n",
    "PATIENCE     = 12\n",
    "HIDDEN_SIZE  = 64\n",
    "NUM_LAYERS   = 2\n",
    "DROPOUT      = 0.2\n",
    "CLIP_NORM    = 1.0\n",
    "\n",
    "# 标定与稳定性（安全阈）\n",
    "RIDGE_L2      = 5e-6\n",
    "B_CAP         = 0.17\n",
    "RHAT_CAP      = 0.023\n",
    "CAL_WIN       = 40\n",
    "MIN_CAL_SAMPLES = 40\n",
    "\n",
    "# 在线均值对齐\n",
    "MEAN_MATCH_WIN = 40\n",
    "MEAN_MATCH_MIN = 20\n",
    "\n",
    "# 展示用“方案A：按块重锚”\n",
    "REBASE_DAYS_FOR_CURVE = 20\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "if device.type == \"cuda\":\n",
    "    try: torch.set_float32_matmul_precision(\"high\")\n",
    "    except: pass\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def last_complete_day():\n",
    "    return (pd.Timestamp.today().normalize() - pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "if END is None: END = last_complete_day()\n",
    "\n",
    "# ==== 纯 PyTorch AdamW（不依赖 torch.optim.*） ====\n",
    "class SimpleAdamW:\n",
    "    def __init__(self, params, lr=1e-3, weight_decay=1e-4, betas=(0.9, 0.999), eps=1e-8):\n",
    "        plist = list(params)\n",
    "        self.params = [p for p in plist if isinstance(p, torch.Tensor) and p.requires_grad]\n",
    "        if not self.params:\n",
    "            raise ValueError(\"Model has no trainable parameters.\")\n",
    "        self.lr, self.wd, self.betas, self.eps = lr, weight_decay, betas, eps\n",
    "        self.state = {}\n",
    "\n",
    "    def zero_grad(self, set_to_none=True):\n",
    "        for p in self.params:\n",
    "            if p.grad is not None:\n",
    "                if set_to_none: p.grad = None\n",
    "                else: p.grad.detach_(); p.grad.zero_()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self):\n",
    "        b1, b2 = self.betas\n",
    "        for p in self.params:\n",
    "            g = p.grad\n",
    "            if g is None: continue\n",
    "            if self.wd:\n",
    "                p.data.mul_(1 - self.lr * self.wd)\n",
    "            st = self.state.get(p)\n",
    "            if st is None:\n",
    "                st = self.state[p] = {\n",
    "                    \"t\": 0,\n",
    "                    \"m\": torch.zeros_like(p, memory_format=torch.preserve_format),\n",
    "                    \"v\": torch.zeros_like(p, memory_format=torch.preserve_format),\n",
    "                }\n",
    "            st[\"t\"] += 1; t = st[\"t\"]\n",
    "            st[\"m\"].mul_(b1).add_(g, alpha=1 - b1)\n",
    "            st[\"v\"].mul_(b2).addcmul_(g, g, value=1 - b2)\n",
    "            m_hat = st[\"m\"] / (1 - b1**t)\n",
    "            v_hat = st[\"v\"] / (1 - b2**t)\n",
    "            p.data.addcdiv_(m_hat, v_hat.sqrt().add_(self.eps), value=-self.lr)\n",
    "\n",
    "# ---------------- Tech Indicators ----------------\n",
    "def rsi(series, n=14):\n",
    "    d = series.diff()\n",
    "    up = d.clip(lower=0); down = -d.clip(upper=0)\n",
    "    ma_up = up.rolling(n, min_periods=n).mean()\n",
    "    ma_dn = down.rolling(n, min_periods=n).mean()\n",
    "    rs = ma_up / ma_dn\n",
    "    return 100 - (100/(1+rs))\n",
    "\n",
    "def macd(close, fast=12, slow=26, signal=9):\n",
    "    ema_f = close.ewm(span=fast, adjust=False).mean()\n",
    "    ema_s = close.ewm(span=slow, adjust=False).mean()\n",
    "    line  = ema_f - ema_s\n",
    "    sig   = line.ewm(span=signal, adjust=False).mean()\n",
    "    hist  = line - sig\n",
    "    return line, sig, hist\n",
    "\n",
    "# 在线均值对齐\n",
    "def online_mean_match(curr_rhat, ret_hist: deque, rhat_hist: deque):\n",
    "    if MEAN_MATCH_WIN is None or len(ret_hist) < MEAN_MATCH_MIN or len(rhat_hist) == 0:\n",
    "        return float(curr_rhat)\n",
    "    mu_true = float(np.mean(ret_hist))\n",
    "    mu_pred = float(np.mean(rhat_hist))\n",
    "    return float(curr_rhat + (mu_true - mu_pred))\n",
    "\n",
    "# ---------------- GRU ----------------\n",
    "class GRUTrend(nn.Module):\n",
    "    def __init__(self, in_dim, hidden=64, layers=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size=in_dim, hidden_size=hidden, num_layers=layers,\n",
    "                          dropout=(dropout if layers>1 else 0.0), batch_first=True)\n",
    "        self.head = nn.Sequential(nn.Dropout(dropout), nn.Linear(hidden, 1))\n",
    "    def forward(self, x):\n",
    "        y, _ = self.gru(x)        # (B,T,H)\n",
    "        last = y[:, -1, :]\n",
    "        logit = self.head(last)   # (B,1)\n",
    "        return logit.squeeze(1)\n",
    "\n",
    "def make_seq_2d_to_3d(X2d: np.ndarray, seq_len: int):\n",
    "    Xs = []\n",
    "    for i in range(seq_len-1, len(X2d)):\n",
    "        Xs.append(X2d[i-seq_len+1:i+1, :])\n",
    "    return np.stack(Xs) if len(Xs)>0 else np.zeros((0, seq_len, X2d.shape[1]), dtype=X2d.dtype)\n",
    "\n",
    "def align_y(y: np.ndarray, seq_len: int):\n",
    "    return y[seq_len-1:]\n",
    "\n",
    "def get_by_key(series: pd.Series, key):\n",
    "    return series.iloc[key] if isinstance(key, (int, np.integer)) else series.loc[key]\n",
    "\n",
    "# ----------- 在线标定器 -----------\n",
    "from collections import deque\n",
    "\n",
    "class OnlineCalibrator:\n",
    "    \"\"\"\n",
    "    维护窗口内的 (z, r)，返回当期 (a_t, b_t) 的闭式岭回归解。\n",
    "    z = p-0.5，r 为次日真实收益（上一日才揭晓）。\n",
    "    \"\"\"\n",
    "    def __init__(self, ridge=1e-6, cap_b=0.10, win=252):\n",
    "        self.ridge = ridge\n",
    "        self.cap_b = cap_b\n",
    "        self.win   = win if (win is None or win > 0) else None\n",
    "\n",
    "        # 重要：不用 maxlen，避免 append 时被动 pop 导致累计和不同步\n",
    "        self.buf = deque()\n",
    "\n",
    "        # 累计量\n",
    "        self.n = 0\n",
    "        self.sz = 0.0; self.sr = 0.0; self.szz = 0.0; self.szr = 0.0\n",
    "\n",
    "    # 仅做“原始加入 + 累计和” (不裁剪)\n",
    "    def _push(self, z, r):\n",
    "        self.buf.append((z, r))\n",
    "        self.n  += 1\n",
    "        self.sz += z\n",
    "        self.sr += r\n",
    "        self.szz += z*z\n",
    "        self.szr += z*r\n",
    "\n",
    "    # 若超过窗口，显式从左侧弹出并同步更新累计和\n",
    "    def _pop_left(self):\n",
    "        if self.win is None: \n",
    "            return\n",
    "        while self.n > self.win:\n",
    "            oldz, oldr = self.buf.popleft()\n",
    "            self.n  -= 1\n",
    "            self.sz -= oldz\n",
    "            self.sr -= oldr\n",
    "            self.szz -= oldz*oldz\n",
    "            self.szr -= oldz*oldr\n",
    "\n",
    "    def add(self, z, r):\n",
    "        self._push(float(z), float(r))\n",
    "        self._pop_left()\n",
    "\n",
    "    def fit_from_arrays(self, z_arr, r_arr):\n",
    "        \"\"\"用历史数组初始化（训练+验证），并裁到窗口；不在遍历时再往同一个 deque 追加。\"\"\"\n",
    "        if len(z_arr) != len(r_arr):\n",
    "            raise ValueError(\"z_arr and r_arr must have the same length\")\n",
    "\n",
    "        # 只取最后 win 条以避免超大历史\n",
    "        if self.win is not None and len(z_arr) > self.win:\n",
    "            z_arr = z_arr[-self.win:]\n",
    "            r_arr = r_arr[-self.win:]\n",
    "\n",
    "        # 直接重建缓冲与累计和\n",
    "        self.buf.clear()\n",
    "        self.buf.extend((float(z), float(r)) for z, r in zip(z_arr, r_arr))\n",
    "\n",
    "        self.n = len(self.buf)\n",
    "        if self.n == 0:\n",
    "            self.sz = self.sr = self.szz = self.szr = 0.0\n",
    "            return\n",
    "\n",
    "        # 重新计算累计量（不改变 buf）\n",
    "        zs = [z for z, _ in self.buf]\n",
    "        rs = [r for _, r in self.buf]\n",
    "        self.sz  = float(np.sum(zs))\n",
    "        self.sr  = float(np.sum(rs))\n",
    "        self.szz = float(np.dot(zs, zs))\n",
    "        self.szr = float(np.dot(zs, rs))\n",
    "\n",
    "    def coef(self):\n",
    "        if self.n < MIN_CAL_SAMPLES:\n",
    "            return None\n",
    "        n, sz, sr, szz, szr = self.n, self.sz, self.sr, self.szz, self.szr\n",
    "        a00 = n + self.ridge\n",
    "        a01 = sz\n",
    "        a11 = szz + self.ridge\n",
    "        b0, b1 = sr, szr\n",
    "        det = a00*a11 - a01*a01\n",
    "        if det <= 1e-18:\n",
    "            return 0.0, 0.0\n",
    "        a = ( b0*a11 - b1*a01) / det\n",
    "        b = ( a00*b1 - a01*b0) / det\n",
    "        b = float(np.clip(b, -self.cap_b, self.cap_b))\n",
    "        return float(a), b\n",
    "\n",
    "\n",
    "# ---------------- 训练（仅 Train/Valid） ----------------\n",
    "def train_with_val(X_train3, y_train1, X_val3, y_val1, n_feat_for_model):\n",
    "    ds_tr = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(X_train3.astype(np.float32)),\n",
    "        torch.from_numpy(y_train1.astype(np.float32)))\n",
    "    ds_va = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(X_val3.astype(np.float32)),\n",
    "        torch.from_numpy(y_val1.astype(np.float32)))\n",
    "    pin = (device.type == \"cuda\")\n",
    "    dl_tr = torch.utils.data.DataLoader(ds_tr, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                                        drop_last=False, pin_memory=pin)\n",
    "    dl_va = torch.utils.data.DataLoader(ds_va, batch_size=2048, shuffle=False,\n",
    "                                        drop_last=False, pin_memory=pin)\n",
    "\n",
    "    model = GRUTrend(n_feat_for_model, hidden=HIDDEN_SIZE, layers=NUM_LAYERS, dropout=DROPOUT).to(device)\n",
    "    opt = SimpleAdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    loss_fn = nn.BCEWithLogitsLoss(\n",
    "        pos_weight=torch.tensor([max(1.0, (len(y_train1)-y_train1.sum())/max(1.0, y_train1.sum()))], device=device)\n",
    "    )\n",
    "\n",
    "    best_state, best_val, bad = None, float(\"inf\"), 0\n",
    "    for _ in range(MAX_EPOCHS):\n",
    "        model.train()\n",
    "        for xb, yb in dl_tr:\n",
    "            xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss = loss_fn(model(xb), yb)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), CLIP_NORM)\n",
    "            opt.step()\n",
    "\n",
    "        model.eval(); vs=[]\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in dl_va:\n",
    "                xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
    "                vs.append(loss_fn(model(xb), yb).item())\n",
    "        v = float(np.mean(vs))\n",
    "        if v < best_val - 1e-9:\n",
    "            best_val, bad = v, 0\n",
    "            best_state = {k: w.detach().clone() for k, w in model.state_dict().items()}\n",
    "        else:\n",
    "            bad += 1\n",
    "            if bad >= PATIENCE: break\n",
    "\n",
    "    if best_state is not None: model.load_state_dict(best_state)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_proba(model, X3):\n",
    "    if len(X3) == 0: return np.array([], dtype=np.float32)\n",
    "    tens = torch.from_numpy(X3.astype(np.float32)).to(device)\n",
    "    return 1/(1+np.exp(-model(tens).cpu().numpy()))\n",
    "\n",
    "# ---------------- Load all data ----------------\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "if not os.path.exists(PRICE_FILE):\n",
    "    raise FileNotFoundError(f\"File not found: {PRICE_FILE}\")\n",
    "\n",
    "df = pd.read_csv(PRICE_FILE, header=[0,1], index_col=0)\n",
    "if isinstance(df.index[0], str) and str(df.index[0]).strip().lower() == \"date\":\n",
    "    df = df.iloc[1:]\n",
    "df.index = pd.to_datetime(df.index, errors=\"coerce\")\n",
    "df = df[~df.index.isna()].sort_index()\n",
    "df = df.loc[(df.index >= START) & (df.index <= END)]\n",
    "\n",
    "all_tickers = df.columns.get_level_values(1).unique().tolist()\n",
    "print(f\"Tickers detected: {len(all_tickers)}; start from #{START_FROM_IDX+1}\")\n",
    "\n",
    "summary = []\n",
    "\n",
    "# ---------------- 主循环：逐个标的 ----------------\n",
    "for TICKER in tqdm(all_tickers[START_FROM_IDX:], desc=f\"All tickers [{START_FROM_IDX+1}→{len(all_tickers)}]\"):\n",
    "    try:\n",
    "        close_s = pd.to_numeric(df[(\"Close\",  TICKER)], errors=\"coerce\")\n",
    "        open_s  = pd.to_numeric(df[(\"Open\",   TICKER)], errors=\"coerce\")\n",
    "        high_s  = pd.to_numeric(df[(\"High\",   TICKER)], errors=\"coerce\")\n",
    "        low_s   = pd.to_numeric(df[(\"Low\",    TICKER)], errors=\"coerce\")\n",
    "        vol_s   = pd.to_numeric(df[(\"Volume\", TICKER)], errors=\"coerce\")\n",
    "    except KeyError:\n",
    "        print(f\"\\n[{TICKER}] missing fields, skip.\"); continue\n",
    "\n",
    "    # 至少要有足够历史\n",
    "    if close_s.dropna().shape[0] < (SEQ_LEN + MIN_TRAIN_DAYS + 50):\n",
    "        print(f\"\\n[{TICKER}] too few points, skip.\"); continue\n",
    "\n",
    "    # ----- Targets -----\n",
    "    y_ret = close_s.shift(-1)/close_s - 1.0\n",
    "    y_cls = (y_ret > 0).astype(int)\n",
    "\n",
    "    # ----- Features (全部 shift(1) 防泄露) -----\n",
    "    feat = pd.DataFrame(index=close_s.index)\n",
    "    feat['ret_c1']  = close_s.pct_change(1)\n",
    "    feat['ret_c5']  = close_s.pct_change(5)\n",
    "    feat['ret_c10'] = close_s.pct_change(10)\n",
    "    feat['ret_c20'] = close_s.pct_change(20)\n",
    "    ma5, ma10, ma20 = close_s.rolling(5).mean(), close_s.rolling(10).mean(), close_s.rolling(20).mean()\n",
    "    feat['ma_gap_5_20']  = (ma5 - ma20)/ma20\n",
    "    feat['ma_gap_10_20'] = (ma10 - ma20)/ma20\n",
    "    feat['oc_1']         = (close_s/open_s - 1.0)\n",
    "    feat['co_1']         = (open_s/close_s.shift(1) - 1.0)\n",
    "    feat['hl_range_5']   = np.log(high_s/low_s).rolling(5).mean()\n",
    "    feat['parkinson10']  = (np.log(high_s/low_s)**2).rolling(10).mean()\n",
    "    logv = np.log(vol_s.replace(0, np.nan))\n",
    "    feat['logv_z21']     = (logv - logv.rolling(21).mean())/logv.rolling(21).std()\n",
    "    m_line, m_sig, m_hist = macd(close_s)\n",
    "    feat['macd']   = m_line; feat['macd_s'] = m_sig; feat['macd_h'] = m_hist\n",
    "    feat['rsi14']  = rsi(close_s, 14)/100.0\n",
    "\n",
    "    feat = feat.shift(1)  # 防泄露\n",
    "\n",
    "    # ----- 对齐 -----\n",
    "    data = pd.concat([feat, y_ret.rename(\"y_ret\"), y_cls.rename(\"y_cls\"), close_s.rename(\"close\")], axis=1).dropna()\n",
    "    if data.shape[0] < (SEQ_LEN + MIN_TRAIN_DAYS + 10):\n",
    "        print(f\"\\n[{TICKER}] not enough aligned samples, skip.\"); continue\n",
    "\n",
    "    X_all   = data.drop(columns=['y_ret','y_cls','close'])\n",
    "    ret_all = data['y_ret']\n",
    "    cls_all = data['y_cls'].astype(int)\n",
    "    close_all = data['close']\n",
    "    dates = X_all.index\n",
    "    n_feat = X_all.shape[1]\n",
    "\n",
    "    # ----- 切分（按日期） -----\n",
    "    train_idx = dates[dates <= pd.Timestamp(TRAIN_END)]\n",
    "    val_idx   = dates[(dates > pd.Timestamp(TRAIN_END)) & (dates <= pd.Timestamp(VAL_END))]\n",
    "    test_idx  = dates[dates > pd.Timestamp(VAL_END)]\n",
    "\n",
    "    if len(train_idx) < SEQ_LEN + MIN_TRAIN_DAYS or len(val_idx) < SEQ_LEN//2 or len(test_idx) < SEQ_LEN:\n",
    "        print(f\"\\n[{TICKER}] split too short (train/val/test), skip.\"); continue\n",
    "\n",
    "    X_train = X_all.loc[train_idx]; y_train_cls = cls_all.loc[train_idx]; y_train_ret = ret_all.loc[train_idx]\n",
    "    X_val   = X_all.loc[val_idx];   y_val_cls   = cls_all.loc[val_idx];   y_val_ret   = ret_all.loc[val_idx]\n",
    "    X_test  = X_all.loc[test_idx];  y_test_ret  = ret_all.loc[test_idx]   # for metrics\n",
    "\n",
    "    # ----- 标准化（仅用训练集拟合） -----\n",
    "    scaler = StandardScaler().fit(X_train.values)\n",
    "\n",
    "    Xtr2 = scaler.transform(X_train.values); Xva2 = scaler.transform(X_val.values)\n",
    "    Xtr3 = make_seq_2d_to_3d(Xtr2, SEQ_LEN); Xva3 = make_seq_2d_to_3d(Xva2, SEQ_LEN)\n",
    "    ytr1 = align_y(y_train_cls.values.astype(np.float32), SEQ_LEN)\n",
    "    yva1 = align_y(y_val_cls.values.astype(np.float32),   SEQ_LEN)\n",
    "\n",
    "    # ----- 仅 Train+Valid 训练 & 早停 -----\n",
    "    model = train_with_val(Xtr3, ytr1, Xva3, yva1, n_feat_for_model=n_feat)\n",
    "\n",
    "    # ----- 用 Train+Valid 的 z,r 初始化在线标定器（模型已冻结） -----\n",
    "    # （标定器是推断期的在线后处理，不改变模型权重）\n",
    "    z_seed, r_seed = [], []\n",
    "    # seed with train\n",
    "    p_tr  = predict_proba(model, make_seq_2d_to_3d(Xtr2, SEQ_LEN))\n",
    "    r_tr  = align_y(y_train_ret.values.astype(np.float32), SEQ_LEN)\n",
    "    z_seed.append(p_tr - 0.5); r_seed.append(r_tr)\n",
    "    # seed with valid\n",
    "    p_va  = predict_proba(model, make_seq_2d_to_3d(Xva2, SEQ_LEN))\n",
    "    r_va  = align_y(y_val_ret.values.astype(np.float32), SEQ_LEN)\n",
    "    z_seed.append(p_va - 0.5); r_seed.append(r_va)\n",
    "\n",
    "    z_seed = np.concatenate(z_seed) if len(z_seed)>0 else np.zeros(0)\n",
    "    r_seed = np.concatenate(r_seed) if len(r_seed)>0 else np.zeros(0)\n",
    "\n",
    "    cal = OnlineCalibrator(ridge=RIDGE_L2, cap_b=B_CAP, win=CAL_WIN)\n",
    "    if len(z_seed) > 0: cal.fit_from_arrays(z_seed, r_seed)\n",
    "\n",
    "    # ======= 测试期：固定模型参数，按时间滚动预测 =======\n",
    "    pred_prob = pd.Series(index=test_idx, dtype=float)\n",
    "    pred_rhat = pd.Series(index=test_idx, dtype=float)\n",
    "\n",
    "    ret_hist  = deque(maxlen=MEAN_MATCH_WIN)\n",
    "    rhat_hist = deque(maxlen=MEAN_MATCH_WIN)\n",
    "\n",
    "    z_prev, prev_j = None, None\n",
    "    for j in test_idx:\n",
    "        X_hist = X_all.loc[:j].values\n",
    "        if len(X_hist) < SEQ_LEN: continue\n",
    "        X_hist_sc = scaler.transform(X_hist)\n",
    "        X_last3   = make_seq_2d_to_3d(X_hist_sc, SEQ_LEN)[-1:,:,:]\n",
    "\n",
    "        p = float(predict_proba(model, X_last3)[0])\n",
    "        z = p - 0.5\n",
    "\n",
    "        coef = cal.coef()\n",
    "        a_t, b_t = (0.0, 0.0) if coef is None else coef\n",
    "\n",
    "        rhat = a_t + b_t * z\n",
    "        rhat = online_mean_match(rhat, ret_hist, rhat_hist)\n",
    "        rhat = float(np.clip(rhat, -RHAT_CAP, RHAT_CAP))\n",
    "\n",
    "        pred_prob.loc[j] = p\n",
    "        pred_rhat.loc[j] = rhat\n",
    "\n",
    "        # 用“昨天”的真实 r 与 r̂ 更新（只用已揭晓历史，不看未来）\n",
    "        if z_prev is not None and prev_j is not None:\n",
    "            cal.add(z_prev, float(get_by_key(ret_all, prev_j)))\n",
    "            ret_hist.append(float(get_by_key(ret_all, prev_j)))\n",
    "            rhat_hist.append(float(pred_rhat.loc[prev_j]))\n",
    "\n",
    "        z_prev, prev_j = z, j\n",
    "\n",
    "    # ---------------- OOS 对齐与“合成价格”(测试期) ----------------\n",
    "    valid = pred_prob.dropna().index\n",
    "    if len(valid)==0:\n",
    "        print(f\"\\n[{TICKER}] no valid test predictions, skip.\")\n",
    "        continue\n",
    "\n",
    "    ret_oos   = y_test_ret.loc[valid]\n",
    "    close_oos = close_all.loc[valid]\n",
    "\n",
    "    # 价格在次日生效：shift(1)；起点锚到测试期首日真实收盘\n",
    "    P0 = float(close_oos.iloc[0])\n",
    "    pred_factor = (1.0 + pred_rhat.loc[valid]).cumprod().shift(1).fillna(1.0)\n",
    "    pred_price  = pd.Series(P0, index=pred_factor.index) * pred_factor\n",
    "\n",
    "    # 方案A：按块重锚（仅展示/统计）\n",
    "    dfp = pd.DataFrame({\"actual\": close_oos, \"pred\": pred_price}).dropna().copy()\n",
    "    blocks_curve = np.arange(len(dfp)) // REBASE_DAYS_FOR_CURVE\n",
    "    def _rebase_block(g: pd.DataFrame):\n",
    "        s = float(g[\"actual\"].iloc[0] / g[\"pred\"].iloc[0])\n",
    "        g[\"pred_rb\"] = g[\"pred\"] * s\n",
    "        return g\n",
    "    dfp = dfp.groupby(blocks_curve, group_keys=False).apply(_rebase_block)\n",
    "    pred_price_rb = dfp[\"pred_rb\"]\n",
    "\n",
    "    # ---------------- 输出 CSV（测试期：Date, PredictedPrice） ----------------\n",
    "    out = pd.DataFrame({\"Date\": valid, \"PredictedPrice\": pred_price.loc[valid].values})\n",
    "    out.to_csv(os.path.join(OUT_DIR, f\"{TICKER}.csv\"), index=False)\n",
    "    print(f\"\\n[{TICKER}] saved -> {TICKER}.csv  (test period)\")\n",
    "\n",
    "    # ---------------- OOS 指标（returns） ----------------\n",
    "    mse_model = float(((ret_oos - pred_rhat.loc[valid])**2).mean())\n",
    "    mse_base  = float(((ret_oos - ret_oos.mean())**2).mean())\n",
    "    r2_oos    = 1 - mse_model/mse_base if mse_base>0 else np.nan\n",
    "    ic        = float(pd.Series(pred_rhat.loc[valid]).corr(ret_oos))\n",
    "    hit       = float((np.sign(pred_rhat.loc[valid])==np.sign(ret_oos)).mean())\n",
    "\n",
    "    # 方向策略的年化Sharpe（仅作参考）\n",
    "    str_ret = np.sign(pred_rhat.loc[valid]) * ret_oos\n",
    "    ann_ret = (1+str_ret.mean())**252 - 1\n",
    "    ann_vol = str_ret.std(ddof=0) * np.sqrt(252)\n",
    "    sharpe  = float(ann_ret/ann_vol) if ann_vol>0 else np.nan\n",
    "\n",
    "    print(f\"[{TICKER}] TEST  MSE={mse_model:.3e} | R2={r2_oos: .3f} | IC={ic: .3f} | Hit={hit: .3f} | Sharpe={sharpe: .2f}\")\n",
    "\n",
    "    summary.append([TICKER, mse_model, r2_oos, ic, hit, sharpe, valid[0].date(), valid[-1].date(), len(valid)])\n",
    "\n",
    "    # ---------------- 画图：实际 vs 预测(重锚) ----------------\n",
    "    plt.figure(figsize=(10,3.2))\n",
    "    plt.plot(close_oos.index, close_oos.values, label=\"Actual Close (USD)\")\n",
    "    plt.plot(pred_price_rb.index, pred_price_rb.values,\n",
    "             label=f\"Predicted (rebased {REBASE_DAYS_FOR_CURVE}d)\")\n",
    "    plt.title(f\"{TICKER} | Actual vs Predicted (TEST)\")\n",
    "    plt.ylabel(\"USD\"); plt.legend(); plt.grid(True, alpha=0.3)\n",
    "    fn = os.path.join(OUT_DIR, f\"{TICKER}_TEST_curve.png\")\n",
    "    plt.tight_layout(); plt.savefig(fn, dpi=140); plt.close()\n",
    "    print(f\"[{TICKER}] saved -> {os.path.basename(fn)}\")\n",
    "\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# ---------------- 汇总输出 ----------------\n",
    "sum_df = pd.DataFrame(summary, columns=[\n",
    "    \"Ticker\",\"MSE\",\"R2_TEST\",\"IC\",\"HitRate\",\"Sharpe\",\"TEST_start\",\"TEST_end\",\"#TEST_days\"\n",
    "])\n",
    "sum_df = sum_df.sort_values(\"R2_TEST\", ascending=False)\n",
    "sum_df.to_csv(os.path.join(OUT_DIR, \"OOS_summary.csv\"), index=False)\n",
    "print(\"\\nSaved OOS_summary.csv\")\n",
    "print(sum_df.head(20).to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
